# 指令操作词、目标词、输入词提取

## 1.1 提取 operation、target 与 input text的方案

### 1.方案一：训练小模型。

- 未找到适合此任务的小模型，所以未能实现方案一。

### 2. 方案二：微调 2B 大模型。

- 模型需要同时对用户操作指令提取出 operation、target 与 input text，但是由于由 DeepSeek 32B 构造的数据集质量不好，所以未能实现方案二。

### **3. 方案三：目标库提取 + 微调 1.8B 大模型**

- 基于构造 operation 与 target 目标库，通过 Embedding model BGE-M3 匹配去查询用户的操作指令，以提取出 operation、target。
- 通过提取出的 operation，判断是否需要提取 input text：
  - 需要则采用 微调后的 1.8B InternLM 提取 input text，返回 operation、target 和 input text。
  - 不需要则直接返回 operation、target 和空 input text

## 1.2 主要挑战与解决方案

### 1. 歧义词处理

**挑战：**

- 某些词（如"备注"、"记录"）既可以是操作词也可以是名词
- 在复杂句式中难以确定其真实语义角色
- 歧义词错误识别会导致整个提取结果不准确
- 例如：在保护患者隐私（减少裸露；不被其他人参观；避免泄露病情；公开场合不讨论患者信息）的备注中写入环境良好无异味

**解决方案：**

- 创建专门的歧义词列表，单独处理识别到的歧义词
- 调整非歧义操作词的匹配阈值设为0.85，防止错误匹配覆盖歧义词
- 在识别到多个操作词时，优先选择非歧义词作为最终操作词

```python
# 歧义词处理代码示例
ambiguous_words = ["备注", "记录", "标记", "注释"]

# 分别存储歧义词和非歧义词候选
ambiguous_candidates = []
op_candidates = []

for i, phrase_emb in enumerate(phrase_embeddings):
    op, score = self._find_best_match(
        phrase_emb, 
        self.operation_embeddings, 
        self.operation_list,
        threshold=0.85  # 提高非歧义词的匹配阈值
    )
    
    if op and score > 0:
        # 判断是否为歧义词
        if op in ambiguous_words:
            ambiguous_candidates.append((op, score))
        else:
            op_candidates.append((op, score))

# 优先使用非歧义词，如果没有非歧义词再考虑歧义词
if not op_candidates and ambiguous_candidates:
    op_candidates = ambiguous_candidates
```

### 2. 长文本目标匹配

**挑战：**

- 所给目标有的非常长
- 固定长度的短语生成不足以捕获完整目标
- 目标描述可能包含特殊符号和复杂结构

**解决方案：**

- 动态调整短语生成的最大长度
- 使用target库中最长目标和当前查询长度的较小值作为上限
- 生成多种长度和组合的短语来增加匹配成功率

```python
# 动态长度目标匹配代码示例
# 找出target库中最长的目标长度
max_target_length = max([len(target) for target in self.targets]) if self.targets else 0

# 计算当前过滤后查询的长度
filtered_query_length = len(filtered_query)

# 取两者的最小值作为最大短语长度
max_phrase_length = min(max_target_length, filtered_query_length)

# 计算最大token数（粗略估计，假设每个token平均2个字符）
max_tokens = max(5, int(max_phrase_length / 2))

# 生成不同长度的短语组合
for phrase_length in range(2, min(max_tokens + 1, len(filtered_tokens) + 1)):
    for i in range(len(filtered_tokens) - phrase_length + 1):
        phrase = ''.join(filtered_tokens[i:i+phrase_length])
        target_phrases.append(phrase)
```

### 3. 长度惩罚调整

**挑战：**

- 短词容易获得高相似度分数但可能不够精确
- 不同长度的词在语义匹配时存在不公平竞争
- 词汇长度与匹配质量之间需要平衡

**解决方案：**

- 对较短的候选项应用长度惩罚因子
- 使用专门的公式计算惩罚系数
- 通过调整惩罚力度平衡短词和长词的匹配优先级

```python
# 长度惩罚调整代码示例
# 计算余弦相似度
similarities = np.dot(candidate_embeddings, query_embedding)

# 对较短的候选项进行轻微的惩罚，避免优先匹配过短的词
length_penalties = np.array([max(0, 1.0 - 0.05 * (5 - min(len(c), 10) / 2)) for c in candidates])
adjusted_similarities = similarities * length_penalties

# 找到最大相似度及其索引
best_idx = np.argmax(adjusted_similarities)
best_score = similarities[best_idx]  # 返回原始相似度分数，不是经过长度调整的
```

### 4. 特殊目标词处理

**挑战：**

- 指令中包含"亮点"、"藏点"、"备注"、"备注点"等特殊词语时的处理
- 这些词在某些情况下本身就应该作为目标，而不仅是操作或修饰词
- 当未匹配到其他目标时，需要有特殊的处理逻辑

**解决方案：**
- 创建特殊目标词列表，用于特殊情况处理
- 当指令中包含这些词且未匹配到目标target，同时操作是写入类时，将这些词直接作为target
- 注意备注点要放在备注之前，若有备注点，优先选择备注点

```python
# 特殊目标词处理代码示例
special_target_words = ["亮点", "藏点","备注点", "备注"]

# 在未找到目标且操作是写入类的情况下进行特殊处理
if not best_target and best_operation in self.operations["输入类"]:
    # 检查原始查询中是否包含特殊目标词
    for special_word in special_target_words:
        if special_word in query:
            best_target = special_word
            best_target_score = 1.0  # 直接指定为最高分
            break
```

### 5. 匹配算法浮点数优化

**挑战：**

- 部分长度长的目标在经过余弦算法后，会出现浮点数精度消失的情况
- 这会同样是完全匹配的情况，子集往往在小数点后会比全集有优势
- 当解决了精度问题后，对于得分相同但长度较长的目标，我们优先选择

**解决方案：**

- 通过round函数解决浮点数丢失问题

- 对于四舍五入后的相同得分，我们采取优先选择较长长度的目标

  ```python
  score = round(score, 5) #解决浮点数精度导致的余弦算法相似度计算错误
  #优先选择长度较长的target
  if score > best_target_score or  (score == best_target_score and len(target) > len(best_target)):
      best_target = target
      best_target_score = score
      original_target = orig_phrase
  ```

### 6. 长文本耗时优化

**挑战：**

- 当写入备注长度过长时，分词+合并子词+匹配 阶段会耗时严重（100+的备注内容 差不多要7s），300+备注内容需要10s多

**解决方案：**

- 进行截断处理，因为operation和target只会出现在开头和结尾部分，那么我们就用target库中默认最大路由+操作词最大的长度+4作为截断范围scope,若当前查询大于2*scope，那么就在开头和结尾分别截断。**此次优化将长文本10s到7s优化至6s到4s**

  ```python
  # 截断处理，操作最长默认4
  scope = self.max_target_length+4+4
  
  if len(query) > 2*scope:
      query = query[:scope] + query[-scope:]
  ```

**解决方案：**

- 通过热点计算，查找出性能瓶颈主要在target的embedding计算(2s-3s)和目标匹配(3s-4s)阶段

- 对于embedding的优化，尝试使用缓存，但效果不佳，应该是cash命中比较少

- 对于目标匹配的优化（这个阶段主要是计算长文本生成的所有子词与target库中的embedding进行余弦相似度计算），通过将原先的for循环改写成numpy矩阵相乘的形式，利用numpy库自带的并行计算，快速计算余弦相似度并进行匹配，成功将余弦相似度匹配阶段的时间优化至**0.3s左右**

  ```python
  # 改前 
  for i, target_emb in enumerate(target_phrase_embeddings):
      target, score, orig_phrase = self._find_best_match(
          target_emb,
          self.target_embeddings,
          self.targets,
          unique_phrases[i],
          threshold=0.85
      )
  ###  _find_best_match函数主体如下
  
          # 计算余弦相似度
          similarities = np.dot(candidate_embeddings, query_embedding)
          
          # 对较短的候选项进行轻微的惩罚，避免优先匹配过短的词
          length_penalties = np.array([max(0, 1.0 - 0.05 * (5 - min(len(c), 10) / 2)) for c in candidates])
  
          adjusted_similarities = similarities * length_penalties
          
          # 找到最大相似度及其索引
          best_idx = np.argmax(adjusted_similarities)
          best_score = similarities[best_idx]  # 返回原始相似度分数，不是经过长度调整的
  
          # print(f"原始短语: {original_phrase}, 候选: {candidates[best_idx]}, 相似度: {best_score:.4f}")
  
  ```

  ```python
  ###更改后
  unique_phrases = list(target_phrases)
              
  # 计算所有短语的embeddings
  target_phrase_embeddings = self._compute_embeddings(unique_phrases)
  
  time_end = time.time()
  print(f"目标短语embedding计算耗时: {time_end - time_start:.2f}秒")
  
  time_start = time.time()
  
  # 向量化计算相似度矩阵
  similarity_matrix = np.dot(target_phrase_embeddings, self.target_embeddings.T)
  
  # 创建长度惩罚向量
  length_penalties = np.array([max(0, 1.0 - 0.05 * (5 - min(len(c), 10) / 2)) for c in self.targets])
  
  # 应用长度惩罚
  adjusted_similarities = similarity_matrix * length_penalties
  
  # 为每个短语找出最佳匹配，但保持原有的比较逻辑
  for i, phrase_similarities in enumerate(similarity_matrix):
      # 找出当前短语的最佳匹配
      best_idx = np.argmax(adjusted_similarities[i])
      score = float(phrase_similarities[best_idx])  # 使用原始相似度
  
      # 应用四舍五入保持精度
      score = round(score, 5)
  
      # 应用阈值过滤
      if score >= 0.85:
          target = self.targets[best_idx]
          orig_phrase = unique_phrases[i]
  
          # 原始的比较逻辑
          if score > best_target_score or (score == best_target_score and len(target) > len(best_target)):
              best_target = target
              best_target_score = score
              original_target = orig_phrase
  ```

### 7. 匹配算法浮点数优化

**挑战：**

- 部分长度长的目标在经过余弦算法后，会出现浮点数精度消失的情况
- 这会同样是完全匹配的情况，子集往往在小数点后会比全集有优势
- 当解决了精度问题后，对于得分相同但长度较长的目标，我们优先选择

**解决方案：**

- 通过round函数解决浮点数丢失问题
- 对于四舍五入后的相同得分，我们采取优先选择较长长度的目标

### 8. 模型微调损失难以下降

**解决方案：**

- 调整学习率、epoch：

- 调整微调 Prompt，最终 Prompt：

  ```
  '你是一名医疗场景下的操作输入提取器，需要将用户操作指令中向目标对象输入的文本提取出来，只需要输出提取出的文本，这对我很重要。现有用户操作指令：“{user_input}”，其中用户的动作为“{ope}”，目标对象为“{tar}”，现在请提取出操作指令中向目标对象输入的文本。'
  ```

### 9. 长文本大模型提取问题

**挑战：**

- 模型对于用户输入文本中的 input text 很长时，只会回答 input text ground truth 的开头部分。

**解决方案：**

- 使用长文本 input text 微调:

  因为上一版使用的微调数据是短文本的 input text，所以会出现这样的问题。
  
  

## 1.3 指令文本长度与推理时间关系

**无需提取 text input：**

受操作指令长度影响小，受网络影响大，当网络良好的情况下，都能1秒内提取出 operation 与 target 。

**需提取 text input：**

| text input GT 长度 | 推理时间 |
| ------------------ | -------- |
| 0 - 50             | < 1 秒   |
| 50 - 200           | < 5秒    |
| 200 +              | > 5 秒   |

**备注：**Embedding model 提取 operation 与 target 时间不超过 3.5秒 （不限文本长度）；微调模型提取 text input 时间长度与 text input ground truth 长度大致呈正相关关系，同时受网络影响。

